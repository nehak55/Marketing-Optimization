{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1) Imagine you are given a plot of land to farm that is 10,000 acres. You know nothing about the land. You have 4 seasons a year in which you can plant and 20 different crops to test out to find the optimal planting time, crop and location. Each crop has a different price it sells for, the same cost to farm and a different output depending on the plot of land/time of year in which it is planted. You have the money to run up to 1000 tests (one test is planting one acre with one crop in one season) per year for 10 years. How would you build an algorithm that would suggest the best 1000 tests for each year/season period to maximize your profit [output x (price – cost)]? Please provide pseudocode for this exercise along with comments/explanation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is scenario of multi-arms bandit problem in reinforcement learning.The objective is to achieve a explore-exploitation trade-off.The epsilon-Greedy algorithm works by randomly oscillating between purely randomized exploration and exploting the best options based on historical conversion rates to maximize profits.The main idea behind the epsilon-Greedy algorithm is : if you flip a coin and it comes up heads, you should explore for a moment. But if the coin comes up tails, you should exploit.\n",
    "\n",
    "The principle behind this problem is given N different arms or options to run the tests to choose from, each with an unknown reward(some quantity which is a measure of success) , what strategy should we use to explore and learn the values of each arm or option, while exploiting our current knowledge to maximize the profit.\n",
    "\n",
    "We also used an epsilon-greedy algorithm where a fraction (1-epsilon) of the time, we choose the arm with the largest estimated value (exploit) and the other fraction (epsilon) chose a random arm (explore). We need to tune the epsilon to balance tradeoff. \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class EpsilonGreedy:\n",
    "    def __init__(self,keys,init,epsilon=0.1):\n",
    "        self.epsilon = epsilon\n",
    "        self.ActionValue = {}\n",
    "        for key in keys:\n",
    "            self.ActionValue[key] = init\n",
    "        \n",
    "    def reward(self,action):\n",
    "        if ActionValue[action][1]*(price-cost) > ActionValue[action][0]*(price-cost): \n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "    \n",
    "    def select_arm(self):\n",
    "        \"\"\"\n",
    "        For 1-epsilon of the time, choose the arm with the highest estimated value.\n",
    "        For epsilon of the time, randomly choose an arm\n",
    "        we’ve implemented this by checking if a randomly generated number is greater than epsilon.\n",
    "        \"\"\"\n",
    "        random_num = np.random.rand()\n",
    "        if random_num<self.epsilon:\n",
    "            return random.choice(self.ActionValue.keys())\n",
    "        else:\n",
    "            return max(self.ActionValue, key=lambda x:self.ActionValue.get(x)[1])\n",
    "        \n",
    "    def update(self,action,reward):\n",
    "        \"\"\"\n",
    "        Update estimated value by keeping running average of rewards for each action\n",
    "        \"\"\"\n",
    "        K = self.ActionValue[action][0]\n",
    "        Value = self.ActionValue[action][1]\n",
    "        K += 1\n",
    "        alpha = 1./K\n",
    "        Value += alpha * (reward - Value)\n",
    "        self.ActionValue[action] = (K,Value)\n",
    "    \n",
    "    def run_test(bandit,Npulls,epsilon):\n",
    "        history = []\n",
    "        for i in range(Npulls):\n",
    "            action = bandit.select_arm(epsilon)\n",
    "            R = bandit.reward(action)\n",
    "            bandit.update(action,R)\n",
    "            history.append(R)\n",
    "            return np.array(history)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Nexp = 1000  # We have 1000 tests \n",
    "Npulls = 10000  # 1 test needs 1 acre of land"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "avg_outcome_eps0 = np.zeros(Npulls)\n",
    "avg_outcome_eps1 = np.zeros(Npulls)\n",
    "avg_outcome_eps2 = np.zeros(Npulls)\n",
    "\n",
    "for i in range(Nexp):\n",
    "    bandit = EpsilonGreedy()\n",
    "    avg_outcome_eps0 += run_test(bandit,Npulls,0.0)\n",
    "    bandit = EpsilonGreedy()\n",
    "    avg_outcome_eps1 += run_test(bandit,Npulls,0.01)\n",
    "    bandit = EpsilonGreedy()\n",
    "    avg_outcome_eps1 += run_test(bandit,Npulls,0.1)\n",
    "\n",
    "avg_outcome_eps0 /= np.float(Nexp)\n",
    "avg_outcome_eps1 /= np.float(Nexp)\n",
    "avg_outcome_eps2 /= np.float(Nexp)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2) What is your favorite machine learning algorithm for predicting a user action in an app (assume the action choice space is discrete and you have access to all the app interaction data). Why? What are the disadvantages of using this algorithm and how could they be overcome or lessened? "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " The machine learning algorithm I would prefer for predicting user action in an app is Dynamic Bayesian Networks. It extends the standard Bayesian Networks that allows us to model both sequences or time series.\n",
    "\n",
    "Advantages:\n",
    "DBNs provide a compact graphical representation of a potentially complex world state. \n",
    "DBN rely on probabilistic foundation, as opposed to the rule and fuzzy logic-based systems. Thus, the numbers that come out have a well-understood interpretation.\n",
    "They are generalization of hidden markov models(HMM), which has exponentially fewer parameters as compared to it's corresponding HMM.\n",
    "\n",
    "\n",
    "Disadvantage:\n",
    "It is not possible sometimes to observe all possible configurations so it is difficult to compute the conditional probabilities of some varibale\n",
    "\n",
    "To avoid zero probabilities, small number called the flattening constant is added to each cell in sparse conditional probability tables. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3) How would you visualize feature weights for a high-dimensional, iterative, predictive algorithm? Can you provide an example (please cite your source if it is not your own visualization)? How would you explain the weight change over iterations to a marketing manager?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Neural networks  are a great analytic tool for predictive modeling like finding which kind of customers are more likely to respond to a marketing campaign. The NeuralNetTools package in R provides interesting visualization of the feature weights and the hidden layers which are captured in the algorithm.\n",
    "\n",
    "Neural networks can be used for visualize feature weights. While there are many packages and tool for visulaizations in R, Python. \n",
    "Below is an interactive visualization source in tensorflow\n",
    "http://playground.tensorflow.org/#activation=tanh&batchSize=10&dataset=circle&regDataset=reg-plane&learningRate=0.03&regularizationRate=0&noise=0&networkShape=4,2&seed=0.57619&showTestData=false&discretize=false&percTrainData=50&x=true&y=true&xTimesY=false&xSquared=false&ySquared=false&cosX=false&sinX=false&cosY=false&sinY=false&collectStats=false&problem=classification&initZero=false&hideText=false\n",
    "\n",
    "Explaining to a marketing manager:\n",
    "\n",
    "\n",
    "Neural networks are based on how a human brain works. It gets set of inputs like car features:mileage of a car, price,number of airbags etc. The hidden layer then processes this information and gives an output whether the customer will like the car or not.The way hidden layer processes the information is by assigning weights to the features based on the customer preference and gives an output. This output is compared to the result which we should have achieved based on previous experience with similar preference and adjusts the weights accordingly in each iteration.\n",
    "\n",
    "This process runs till correct prediction is made( that is model is able to predict accurately whether a customer will like a car or not)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4) What decision rule would you use for stopping a Bayesian AB test? Why would you use this rule and what are its advantages and disadvantages? Please provide pseudocode for how you would implement the statistical calculations for this rule."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reference1: http://varianceexplained.org/r/bayesian-ab-testing/\n",
    "\n",
    "Reference2:http://andrewgelman.com/2014/02/13/stopping-rules-bayesian-analysis/\n",
    "\n",
    "Reference3: http://doingbayesiandataanalysis.blogspot.com/2013/11/optional-stopping-in-data-collection-p.html\n",
    "          \n",
    "           \n",
    "          \n",
    "\n",
    "The rule that can be used to stopping a Bayesian A/B test is to use a desired degree of precision.\n",
    "The rule is to stop when a version appears better than the alternative with a probability of 95%.\n",
    "\n",
    "Advantage: The rule is unbiassed: it is looking for a result, but not a specific result.\n",
    "Disadvantage:False positives and peeking are still an issue in Bayesian testing\n",
    "         \n",
    "\n",
    "The disadvantage of the rule is that there is a requirement for a faily large sample and the curves might lead misleadingly over a larger sample size even when the data collection has stopped.  \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pseducode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n.trials = 10000\n",
    "\n",
    "p.A = 0.05\n",
    "p.B = 0.05\n",
    "\n",
    "cat(\"unbiased stopping rule (stop on any positive)\\n\")\n",
    "for (optional.stops in 0:10) {\n",
    "    cnt.positives = 0\n",
    "    for (idx.trial in 1:n.trials) {\n",
    "        n.A = 1500\n",
    "        n.B = 750\n",
    "\n",
    "        obs.A = rbinom(1,n.A,p.A)\n",
    "        obs.B = rbinom(1,n.B,p.B)\n",
    "        p.A.samples = rbeta(10000,obs.A+1,n.A-obs.A+1) # simulate from the posterior distribution of A\n",
    "        p.B.samples = rbeta(10000,obs.B+1,n.B-obs.B+1)\n",
    "        delta.samples = p.A.samples - p.B.samples\n",
    "\n",
    "        ## Stop the experiment if either version appears better with > 95% probability.\n",
    "        positive.result = .95 < mean(delta.samples < 0) || .95 < mean(0 < delta.samples)\n",
    "\n",
    "        if (0 < optional.stops) {\n",
    "            ## If optional stopping is enabled and we haven't reached a conclusion yet,\n",
    "            ## collect another 100 samples for A & B and decide again if we should stop the experiment.\n",
    "            for (i in 1:optional.stops) {\n",
    "                if (positive.result)\n",
    "                    break\n",
    "\n",
    "                obs.A = obs.A + rbinom(1,100,p.A)\n",
    "                n.A = n.A + 100\n",
    "                obs.B = obs.B + rbinom(1,100,p.B)\n",
    "                n.B = n.B + 100\n",
    "\n",
    "                p.A.samples = rbeta(10000,obs.A+1,n.A-obs.A+1)\n",
    "                p.B.samples = rbeta(10000,obs.B+1,n.B-obs.B+1)\n",
    "                delta.samples = p.A.samples - p.B.samples\n",
    "\n",
    "                positive.result = .95 < mean(delta.samples < 0) || .95 < mean(0 < delta.samples)\n",
    "            }\n",
    "        }\n",
    "\n",
    "        if (positive.result)\n",
    "            cnt.positives = cnt.positives + 1\n",
    "    }\n",
    "    cat(sprintf(\"%d optional stops: positive rate: %d/%d = %f\\n\",\n",
    "                optional.stops,cnt.positives,n.trials,cnt.positives/n.trials))\n",
    "}"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [default]",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
